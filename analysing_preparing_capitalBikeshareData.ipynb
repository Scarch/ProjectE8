{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Making Capital Bikeshare system data usable",
   "id": "46889185c62f4528"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Unzipping files\n",
    "\n",
    "We'll add all of the files into a new folder (`/unzippedData`)\n",
    "\n",
    "**Warning**: requires at least 5.63GB of space"
   ],
   "id": "634e9323845fc0f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T10:12:31.803808Z",
     "start_time": "2024-12-03T10:12:01.615518Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "for file in os.listdir(\"./capitalBikeshareData\"):\n",
    "    filepath = \"./capitalBikeshareData/\" + file\n",
    "    with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./unzippedData\")"
   ],
   "id": "1ece8cde5822e77c",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analysing data before any further data preparation\n",
    "\n",
    "Since we want to work on as much data as possible, we want to combine the data into one csv file. This however requires the csv files to be the same for the most part. The most important part is for each of the csv files to each have similar/same features. Let's check that."
   ],
   "id": "a3a98778fc575ae0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T10:14:29.242540Z",
     "start_time": "2024-12-03T10:12:31.828544Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "columnNamesDict = dict()\n",
    "for file in os.listdir(\"./unzippedData\"):\n",
    "    filepath = \"./unzippedData/\" + file\n",
    "    if not os.path.isfile(filepath):\n",
    "        continue\n",
    "    fileDataframe = pd.read_csv(filepath, low_memory=False)\n",
    "    columnNames = \"\"\n",
    "    for name in fileDataframe.columns:\n",
    "        columnNames += name + \", \"\n",
    "    columnNames = columnNames[:-2]\n",
    "    if columnNames not in columnNamesDict:\n",
    "        print(filepath)\n",
    "        print(columnNames + \"\\n\")\n",
    "        columnNamesDict[columnNames] = fileDataframe.columns.values.tolist()\n"
   ],
   "id": "96f92d72aff7a185",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./unzippedData/2010-capitalbikeshare-tripdata.csv\n",
      "Duration, Start date, End date, Start station number, Start station, End station number, End station, Bike number, Member type\n",
      "\n",
      "./unzippedData/202004-capitalbikeshare-tripdata.csv\n",
      "ride_id, rideable_type, started_at, ended_at, start_station_name, start_station_id, end_station_name, end_station_id, start_lat, start_lng, end_lat, end_lng, member_casual\n",
      "\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Csv files before April 2020 have columns `Duration`, `Start date`, `End date`, `Start station number`, `Start station`, `End station number`, `End station`, `Bike number`, `Member type`.\n",
    "\n",
    "Csv files after April 2020 have columns `ride_id`, `rideable_type`, `started_at`, `ended_at`, `start_station_name`, `start_station_id`, `end_station_name`, `end_station_id`, `start_lat`, `start_lng`, `end_lat`, `end_lng`, `member_casual`.\n",
    "\n",
    "We can see that Capital Bikeshare decided to implement coordinates into their data alongside stations. This likely comes from the fact that you can leave your bike or rent a bike in locations that don't classify under a station, which requires assigning a longitude and latitude value.\n",
    "\n",
    "These factors make combining datasets difficult.\n"
   ],
   "id": "3de0b71818dff39e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Combining data into single files based on features\n",
    "\n",
    "Since we have two different sets of column names / features for two different time ranges, we'll try to make one csv file for both sets.\n",
    "\n",
    "**Warning**: takes a long time (~8 minutes) and requires at least 5.63 GB of space"
   ],
   "id": "c915903b62f3bdfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T10:24:19.919835Z",
     "start_time": "2024-12-03T10:14:29.544902Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "combinedDataBeforeApril2020 = pd.DataFrame(\n",
    "    {'Duration': [], 'Start date': [], 'End date': [], 'Start station number': [],\n",
    "     'Start station': [], 'End station number': [], 'End station': [], 'Bike number': [],\n",
    "     'Member type': []})\n",
    "\n",
    "combinedDataAfterApril2020 = pd.DataFrame({'ride_id': [], 'rideable_type': [], 'started_at': [], 'ended_at': [],\n",
    "                                           'start_station_name': [],\n",
    "                                           'start_station_id': [], 'end_station_name': [], 'end_station_id': [],\n",
    "                                           'start_lat': [],\n",
    "                                           'start_lng': [],\n",
    "                                           'end_lat': [], 'end_lng': [], 'member_casual': []})\n",
    "\n",
    "columnNamesDict = set()\n",
    "for file in os.listdir(\"./unzippedData\"):\n",
    "    filepath = \"./unzippedData/\" + file\n",
    "\n",
    "    if not os.path.isfile(filepath):\n",
    "        continue\n",
    "\n",
    "    fileDataframe = pd.read_csv(filepath, low_memory=False,\n",
    "                                dtype=\"string\")  # String type is important to not convert integers into floats (becomes a problem by adding .0 to the end of an integer)\n",
    "\n",
    "    if fileDataframe.columns[0] == 'ride_id':\n",
    "        combinedDataAfterApril2020 = pd.concat([combinedDataAfterApril2020, fileDataframe], ignore_index=True)\n",
    "    else:\n",
    "        combinedDataBeforeApril2020 = pd.concat([combinedDataBeforeApril2020, fileDataframe], ignore_index=True)\n",
    "\n",
    "combinedDataAfterApril2020.to_csv('./combinedDataAfterApril2020.csv')\n",
    "\n",
    "combinedDataBeforeApril2020.to_csv('./combinedDataBeforeApril2020.csv')"
   ],
   "id": "a2f8f232afb6bf8c",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Assembling a combined csv file based on common features\n",
    "\n",
    "Since the features after April 2020 are named better, we'll try to use their names.\n",
    "\n",
    "**Warning**: takes a long time and requires at least 5.63 GB of space"
   ],
   "id": "ce532e0257b8ac79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T10:32:00.591143Z",
     "start_time": "2024-12-03T10:24:19.960366Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function for assigning correct datatypes\n",
    "def set_data_types_combined(df):\n",
    "    df['started_at'] = pd.to_datetime(df['started_at'], format='ISO8601', yearfirst=True)\n",
    "    df['ended_at'] = pd.to_datetime(df['started_at'], format='ISO8601', yearfirst=True)\n",
    "    df.astype({\"is_member\": \"bool\"})\n",
    "\n",
    "\n",
    "trimmedDataAfterApril2020 = pd.read_csv('./combinedDataAfterApril2020.csv', low_memory=False, index_col=0,\n",
    "                                        dtype={\"Start station number\": \"string\", \"End station number\": \"string\"})\n",
    "trimmedDataAfterApril2020.drop(columns=[\"ride_id\", \"rideable_type\", \"start_lat\", \"end_lat\", \"start_lng\", \"end_lng\"],\n",
    "                               axis=1, inplace=True)\n",
    "trimmedDataAfterApril2020.columns = [\"started_at\", \"ended_at\", \"start_station_name\", \"start_station_id\",\n",
    "                                     \"end_station_name\", \"end_station_id\", \"is_member\"]\n",
    "trimmedDataAfterApril2020.loc[trimmedDataAfterApril2020['is_member'] == \"member\", 'is_member'] = True\n",
    "trimmedDataAfterApril2020.loc[trimmedDataAfterApril2020['is_member'] == \"casual\", 'is_member'] = False\n",
    "\n",
    "trimmedDataBeforeApril2020 = pd.read_csv('./combinedDataBeforeApril2020.csv', low_memory=False, index_col=0,\n",
    "                                         dtype={\"start_station_id\": \"string\", \"end_station_id\": \"string\"})\n",
    "trimmedDataBeforeApril2020.drop(columns=[\"Duration\", \"Bike number\"], axis=1, inplace=True)\n",
    "trimmedDataBeforeApril2020.columns = [\"started_at\", \"ended_at\", \"start_station_id\", \"start_station_name\",\n",
    "                                      \"end_station_id\", \"end_station_name\", \"is_member\"]\n",
    "trimmedDataBeforeApril2020.loc[trimmedDataBeforeApril2020['is_member'] == \"Member\", 'is_member'] = True\n",
    "trimmedDataBeforeApril2020.loc[trimmedDataBeforeApril2020['is_member'] == \"Casual\", 'is_member'] = False\n",
    "\n",
    "combinedData = pd.concat([trimmedDataAfterApril2020, trimmedDataBeforeApril2020], ignore_index=True)\n",
    "set_data_types_combined(combinedData)\n",
    "combinedData.to_csv('./combinedData.csv')"
   ],
   "id": "f41040a714a1872b",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# In-depth analysis",
   "id": "a06ad1108471ee5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analysing data in greater detail\n",
    "\n",
    "Now that we have multiple large datasets, we can do further investigation into how good our data is.\n",
    "\n",
    "Things that we'll check in no particular order:\n",
    "- Checking if station IDs always go together with the same name\n",
    "- Checking the amount of empty fields"
   ],
   "id": "66aba540aa85f17f"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T19:17:04.133427Z",
     "start_time": "2024-12-03T19:04:00.963682Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Loading in data if required, takes a long time\n",
    "# import pandas as pd\n",
    "import cudf as pd\n",
    "\n",
    "combinedData = pd.read_csv('./combinedData.csv', index_col=0,\n",
    "                           dtype={\"start_station_id\": \"string\",\n",
    "                                  \"end_station_id\": \"string\"})  # low_memory=False if reading with pandas\n",
    "combinedDataAfterApril2020 = pd.read_csv('./combinedDataAfterApril2020.csv')\n",
    "combinedDataBeforeApril2020 = pd.read_csv('./combinedDataBeforeApril2020.csv')"
   ],
   "id": "1ff8b09d4950fa1",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking for empty fields",
   "id": "8d408991db045904"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T10:56:08.717855Z",
     "start_time": "2024-12-03T10:55:33.277478Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def print_empty_statistics(df):\n",
    "    print(\"Amount of rows e.g. bike rides:\", f\"{len(df):,}\")\n",
    "    rows_with_empty_fields = df.shape[0] - df.dropna().shape[0]\n",
    "    print(\"Amount of rows in combined dataset with empty fields\", f\"{rows_with_empty_fields:,}\")\n",
    "    print(\"Percentage of data with empty fields:\", \"~\" + str(round(rows_with_empty_fields / len(df) * 100, 3)) + \"%\")\n",
    "\n",
    "\n",
    "print(\"Combined data:\")\n",
    "print_empty_statistics(combinedData)\n",
    "print()\n",
    "\n",
    "print(\"Data before April 2020:\")\n",
    "print_empty_statistics(combinedDataBeforeApril2020)\n",
    "print()\n",
    "\n",
    "print(\"Data after April 2020:\")\n",
    "print_empty_statistics(combinedDataAfterApril2020)\n",
    "print()\n",
    "\n"
   ],
   "id": "4eea249849f8b94f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data:\n",
      "Amount of rows e.g. bike rides: 37,554,003\n",
      "Amount of rows in combined dataset with empty fields 2,581,716\n",
      "Percentage of data with empty fields: ~6.875%\n",
      "\n",
      "Data before april 2020:\n",
      "Amount of rows e.g. bike rides: 20,380,277\n",
      "Amount of rows in combined dataset with empty fields 14\n",
      "Percentage of data with empty fields: ~0.0%\n",
      "\n",
      "Data after april 2020:\n",
      "Amount of rows e.g. bike rides: 17,173,726\n",
      "Amount of rows in combined dataset with empty fields 2,581,726\n",
      "Percentage of data with empty fields: ~15.033%\n",
      "\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "As we can see, about 7% of the combined dataset has empty fields with most of the empty fields originating from the data after April 2020.",
   "id": "8a0fe1c6e0822df4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:09:09.326948Z",
     "start_time": "2024-12-03T11:09:02.753347Z"
    }
   },
   "cell_type": "code",
   "source": "combinedDataAfterApril2020.isna().sum()",
   "id": "be5b71003d960364",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ride_id                     0\n",
       "rideable_type               0\n",
       "started_at                  0\n",
       "ended_at                    0\n",
       "start_station_name    1763763\n",
       "start_station_id      1763763\n",
       "end_station_name      1880096\n",
       "end_station_id        1880914\n",
       "start_lat                  10\n",
       "start_lng                  10\n",
       "end_lat                 26620\n",
       "end_lng                 26620\n",
       "member_casual               0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "The main problem that creates the large amounts of empty fields is that Capital Bikeshare implemented a coordinate system, as we discussed in the chapter about column names. When people leave a bike or rent a bike at a location that isn't a designated station, then the appropriate field is left empty.",
   "id": "1521bb94161ba35a"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T11:28:01.311512Z",
     "start_time": "2024-12-03T11:27:56.052242Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Empty fields in the data before April 2020\")\n",
    "empty_fields_before_42020 = combinedDataBeforeApril2020.isna().sum()\n",
    "for column in combinedDataBeforeApril2020.columns:\n",
    "    if empty_fields_before_42020[column] != 0:\n",
    "        print(column + \":\", empty_fields_before_42020[column])"
   ],
   "id": "7d1002ebb3152b6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty fields in the data before April 2020\n",
      "Bike number: 14\n"
     ]
    }
   ],
   "execution_count": 25
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Seems like the only source of empty fields in the data before April 2020 is the bike numbers. This however is such a tiny sum, that we can easily remove the related rows without worry.",
   "id": "e1e90bcd7c08d192"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Checking if all station IDs align with their names",
   "id": "375e9bb548240608"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T19:26:41.142071Z",
     "start_time": "2024-12-03T19:25:18.325553Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cudf as pd\n",
    "\n",
    "name_to_id_dictionary = dict()\n",
    "id_to_name_dictionary = dict()\n",
    "\n",
    "\n",
    "def add_second_column_value_to_dict_based_on_first(df, first_column, second_column, dictionary):\n",
    "    for index, dataframeRow in df.to_pandas().iterrows():\n",
    "        first_attribute = dataframeRow[first_column]\n",
    "        second_attribute = dataframeRow[second_column]\n",
    "        if first_attribute is None or second_attribute is None:\n",
    "            continue\n",
    "        if first_attribute in dictionary:\n",
    "            if dictionary[first_attribute] != second_attribute:\n",
    "                print(\"Column\", first_column, \"value\", first_attribute, \"has two different\", second_column, \"values:\",\n",
    "                      dictionary[first_attribute], second_attribute)\n",
    "                break\n",
    "        else:\n",
    "            dictionary[first_attribute] = second_attribute\n",
    "\n",
    "\n",
    "add_second_column_value_to_dict_based_on_first(combinedData, 'start_station_name', 'start_station_id',\n",
    "                                               name_to_id_dictionary)\n",
    "add_second_column_value_to_dict_based_on_first(combinedData, 'start_station_id', 'start_station_name',\n",
    "                                               id_to_name_dictionary)"
   ],
   "id": "ff60c57fb646d0f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column start_station_name value 16th & Harvard St NW has two different start_station_id values: 31135 31103\n",
      "Column start_station_id value 31339 has two different start_station_name values: 18th St & Ingleside Ter NW 18th St & Ingleside Terr NW\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Seems that we have stations with multiple IDs and IDs that correspond to multiple stations. Seems like some stations might have been renamed at some point, which explains one ID having multiple names attached to it, but one station having multiple IDs doesn't make much sense. Aside from the fact that this makes things confusing, it might also complicate later model creation, if one were to predict something off of this data. A solution for this is to manually assign a unique id to each station name.",
   "id": "52ed51d022e092fd"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Formatting data to be in line with that of the Kaggle competition\n",
    "\n",
    "As the title says, we'll try to make use of this system data to possibly give us a more accurate model for predicting bike rental demand."
   ],
   "id": "411fb63b0d5577b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T19:46:04.136830Z",
     "start_time": "2024-12-03T19:44:06.604008Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "combinedData = pd.read_csv('./combinedData.csv', index_col=0, low_memory=False,\n",
    "                           dtype={\"start_station_id\": \"string\",\n",
    "                                  \"end_station_id\": \"string\"})  # low_memory=False if reading with pandas\n",
    "\n",
    "combinedData['started_at'] = pd.to_datetime(combinedData['started_at'], format='ISO8601')\n"
   ],
   "id": "aa7eef7eb43da34d",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Counting each bike ride in a specific hour\n",
    "\n",
    "We'll count by rounding down (i.e. using the floor function) the `started_at` attribute of each row in the combined dataset."
   ],
   "id": "7ae13637f9aaa8be"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T20:46:33.771498Z",
     "start_time": "2024-12-03T20:46:22.231207Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Counting amounts of bikes rented\n",
    "bikesRentedPerHourCombinedData = pd.DataFrame(combinedData['started_at'].dt.floor('h').value_counts())\n",
    "bikesRentedPerHourCombinedData.index.name = \"datetime\"\n",
    "bikesRentedPerHourCombinedData.reset_index(inplace=True)  # Moving datetime into a separate column\n",
    "\n",
    "# Sorting\n",
    "bikesRentedPerHourCombinedData.sort_values(inplace=True, by='datetime')\n",
    "bikesRentedPerHourCombinedData.reset_index(inplace=True, drop=True)\n",
    "\n",
    "# Inserting datetimes, where no bikes were rented\n",
    "date_list = pd.date_range(bikesRentedPerHourCombinedData['datetime'].iloc[0],\n",
    "                          bikesRentedPerHourCombinedData['datetime'].iloc[-1], freq=\"h\")\n",
    "\n",
    "# Checking if a datetime appears in our dataset\n",
    "empty_datetimes = {'datetime': [], 'count': []}\n",
    "for date in date_list:\n",
    "    if date not in bikesRentedPerHourCombinedData['datetime'].values:\n",
    "        empty_datetimes['datetime'].append(date)\n",
    "        empty_datetimes['count'].append(0)\n",
    "empty_datetimes = pd.DataFrame(empty_datetimes)\n",
    "\n",
    "# Adding the empty datetimes to the dataset\n",
    "bikesRentedPerHourCombinedData = pd.concat([bikesRentedPerHourCombinedData, empty_datetimes], ignore_index=True)\n",
    "\n",
    "# Sorting\n",
    "bikesRentedPerHourCombinedData.sort_values(inplace=True, by='datetime')\n",
    "bikesRentedPerHourCombinedData.reset_index(inplace=True, drop=True)\n",
    "\n",
    "display(bikesRentedPerHourCombinedData)"
   ],
   "id": "1efef4de32c46efc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  datetime  count\n",
       "0      2010-09-20 11:00:00      2\n",
       "1      2010-09-20 12:00:00     17\n",
       "2      2010-09-20 13:00:00     11\n",
       "3      2010-09-20 14:00:00      6\n",
       "4      2010-09-20 15:00:00     12\n",
       "...                    ...    ...\n",
       "123728 2024-10-31 19:00:00   1561\n",
       "123729 2024-10-31 20:00:00   1249\n",
       "123730 2024-10-31 21:00:00   1182\n",
       "123731 2024-10-31 22:00:00    939\n",
       "123732 2024-10-31 23:00:00    511\n",
       "\n",
       "[123733 rows x 2 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-09-20 11:00:00</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-09-20 12:00:00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-09-20 13:00:00</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-09-20 14:00:00</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-09-20 15:00:00</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123728</th>\n",
       "      <td>2024-10-31 19:00:00</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123729</th>\n",
       "      <td>2024-10-31 20:00:00</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123730</th>\n",
       "      <td>2024-10-31 21:00:00</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123731</th>\n",
       "      <td>2024-10-31 22:00:00</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123732</th>\n",
       "      <td>2024-10-31 23:00:00</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123733 rows × 2 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 66
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Assigning season, holiday and workingday values",
   "id": "82b68b4a9562077c"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-03T20:50:54.251429Z",
     "start_time": "2024-12-03T20:50:41.659919Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from datetime import date, datetime\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "\n",
    "# Code for determining season (taken from https://stackoverflow.com/a/28688724)\n",
    "\n",
    "Y = 2000  # dummy leap year to allow input X-02-29 (leap day)\n",
    "seasons = [(1, (date(Y, 1, 1), date(Y, 3, 20))),\n",
    "           (2, (date(Y, 3, 21), date(Y, 6, 20))),\n",
    "           (3, (date(Y, 6, 21), date(Y, 9, 22))),\n",
    "           (4, (date(Y, 9, 23), date(Y, 12, 20))),\n",
    "           (1, (date(Y, 12, 21), date(Y, 12, 31)))]\n",
    "\n",
    "\n",
    "def get_season(now):\n",
    "    if isinstance(now, datetime):\n",
    "        now = now.date()\n",
    "    now = now.replace(year=Y)\n",
    "    return next(season for season, (start, end) in seasons\n",
    "                if start <= now <= end)\n",
    "\n",
    "\n",
    "# Code for assigning holiday values\n",
    "cal = USFederalHolidayCalendar()\n",
    "holidays = cal.holidays(start='2009-01-01', end='2025-12-31').to_pydatetime()\n",
    "\n",
    "season_assignments = []\n",
    "holiday_assignments = []\n",
    "workingday_assignments = []\n",
    "for idx, row in bikesRentedPerHourCombinedData.iterrows():\n",
    "    season_assignments.append(get_season(row['datetime']))\n",
    "    if row['datetime'] in holidays:\n",
    "        holiday_assignments.append(1)\n",
    "        workingday_assignments.append(1)\n",
    "    else:\n",
    "        holiday_assignments.append(0)\n",
    "        if row['datetime'].weekday() <= 4:\n",
    "            workingday_assignments.append(1)\n",
    "        else:\n",
    "            workingday_assignments.append(0)\n",
    "\n",
    "bikesRentedPerHourCombinedData['season'] = season_assignments\n",
    "bikesRentedPerHourCombinedData['holiday'] = holiday_assignments\n",
    "bikesRentedPerHourCombinedData['workingday'] = workingday_assignments\n",
    "\n",
    "bikesRentedPerHourCombinedData.to_csv('./bikesRentedPerHourCombinedData.csv', index=False)\n",
    "\n",
    "display(bikesRentedPerHourCombinedData)"
   ],
   "id": "ead413d943e763ea",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                  datetime  count  season  holiday  workingday\n",
       "0      2010-09-20 11:00:00      2       3        0           1\n",
       "1      2010-09-20 12:00:00     17       3        0           1\n",
       "2      2010-09-20 13:00:00     11       3        0           1\n",
       "3      2010-09-20 14:00:00      6       3        0           1\n",
       "4      2010-09-20 15:00:00     12       3        0           1\n",
       "...                    ...    ...     ...      ...         ...\n",
       "123728 2024-10-31 19:00:00   1561       4        0           1\n",
       "123729 2024-10-31 20:00:00   1249       4        0           1\n",
       "123730 2024-10-31 21:00:00   1182       4        0           1\n",
       "123731 2024-10-31 22:00:00    939       4        0           1\n",
       "123732 2024-10-31 23:00:00    511       4        0           1\n",
       "\n",
       "[123733 rows x 5 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>count</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-09-20 11:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-09-20 12:00:00</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-09-20 13:00:00</td>\n",
       "      <td>11</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-09-20 14:00:00</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-09-20 15:00:00</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123728</th>\n",
       "      <td>2024-10-31 19:00:00</td>\n",
       "      <td>1561</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123729</th>\n",
       "      <td>2024-10-31 20:00:00</td>\n",
       "      <td>1249</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123730</th>\n",
       "      <td>2024-10-31 21:00:00</td>\n",
       "      <td>1182</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123731</th>\n",
       "      <td>2024-10-31 22:00:00</td>\n",
       "      <td>939</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123732</th>\n",
       "      <td>2024-10-31 23:00:00</td>\n",
       "      <td>511</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123733 rows × 5 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 69
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Assigning weather values\n",
    "\n",
    "We can assign temperature, apparent temperature and humidity first."
   ],
   "id": "d5ea86145f5cdfe3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T20:32:18.511867Z",
     "start_time": "2024-12-05T20:31:25.759436Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Importing the previously made data\n",
    "bikesRentedPerHourCombinedData = pd.read_csv('./bikesRentedPerHourCombinedData.csv')\n",
    "bikesRentedPerHourCombinedData['datetime'] = pd.to_datetime(bikesRentedPerHourCombinedData['datetime'],\n",
    "                                                            format='ISO8601')\n",
    "\n",
    "# Importing weather data (provided by Open-Meteo)\n",
    "weatherData2010JanTo2024Dec = pd.read_csv('./open-meteo-38.91N77.07W12m.csv', skiprows=[0, 1, 2])\n",
    "weatherData2010JanTo2024Dec['time'] = pd.to_datetime(weatherData2010JanTo2024Dec['time'], format='ISO8601')\n",
    "\n",
    "temperature_assignments = []\n",
    "apparent_temperature_assignments = []\n",
    "humidity_assignments = []\n",
    "for idx, row in bikesRentedPerHourCombinedData.iterrows():\n",
    "    weatherRow = weatherData2010JanTo2024Dec[weatherData2010JanTo2024Dec['time'] == row['datetime']]\n",
    "    temperature_assignments.append(weatherRow.iloc[0]['temperature_2m (°C)'])\n",
    "    apparent_temperature_assignments.append(weatherRow.iloc[0]['apparent_temperature (°C)'])\n",
    "    humidity_assignments.append(weatherRow.iloc[0]['relative_humidity_2m (%)'])\n",
    "\n",
    "bikesRentedPerHourCombinedData['temp'] = temperature_assignments\n",
    "bikesRentedPerHourCombinedData['atemp'] = apparent_temperature_assignments\n",
    "bikesRentedPerHourCombinedData['humidity'] = humidity_assignments\n",
    "\n",
    "display(weatherData2010JanTo2024Dec)"
   ],
   "id": "4c06cd6a22845955",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                      time  temperature_2m (°C)  relative_humidity_2m (%)  \\\n",
       "0      2010-01-01 00:00:00                  0.8                      99.0   \n",
       "1      2010-01-01 01:00:00                  0.8                      99.0   \n",
       "2      2010-01-01 02:00:00                 -0.1                      99.0   \n",
       "3      2010-01-01 03:00:00                  0.1                      99.0   \n",
       "4      2010-01-01 04:00:00                 -0.2                      99.0   \n",
       "...                    ...                  ...                       ...   \n",
       "130819 2024-12-03 19:00:00                  0.1                      53.0   \n",
       "130820 2024-12-03 20:00:00                  NaN                       NaN   \n",
       "130821 2024-12-03 21:00:00                  NaN                       NaN   \n",
       "130822 2024-12-03 22:00:00                  NaN                       NaN   \n",
       "130823 2024-12-03 23:00:00                  NaN                       NaN   \n",
       "\n",
       "        apparent_temperature (°C)  precipitation (mm)  rain (mm)  \\\n",
       "0                            -1.4                 0.1        0.1   \n",
       "1                            -1.4                 0.2        0.2   \n",
       "2                            -2.6                 0.0        0.0   \n",
       "3                            -2.6                 0.0        0.0   \n",
       "4                            -3.0                 0.0        0.0   \n",
       "...                           ...                 ...        ...   \n",
       "130819                       -5.2                 0.0        0.0   \n",
       "130820                        NaN                 NaN        NaN   \n",
       "130821                        NaN                 NaN        NaN   \n",
       "130822                        NaN                 NaN        NaN   \n",
       "130823                        NaN                 NaN        NaN   \n",
       "\n",
       "        snowfall (cm)  weather_code (wmo code)  cloud_cover (%)  \\\n",
       "0                 0.0                     51.0             99.0   \n",
       "1                 0.0                     51.0             95.0   \n",
       "2                 0.0                      3.0            100.0   \n",
       "3                 0.0                      3.0             82.0   \n",
       "4                 0.0                      2.0             65.0   \n",
       "...               ...                      ...              ...   \n",
       "130819            0.0                      0.0              0.0   \n",
       "130820            NaN                      NaN              NaN   \n",
       "130821            NaN                      NaN              NaN   \n",
       "130822            NaN                      NaN              NaN   \n",
       "130823            NaN                      NaN              NaN   \n",
       "\n",
       "        wind_speed_10m (km/h)  wind_speed_100m (km/h)  \n",
       "0                         1.5                     2.0  \n",
       "1                         1.6                     1.3  \n",
       "2                         2.5                     4.7  \n",
       "3                         3.6                     7.0  \n",
       "4                         4.3                     9.3  \n",
       "...                       ...                     ...  \n",
       "130819                   14.7                    30.2  \n",
       "130820                    NaN                     NaN  \n",
       "130821                    NaN                     NaN  \n",
       "130822                    NaN                     NaN  \n",
       "130823                    NaN                     NaN  \n",
       "\n",
       "[130824 rows x 11 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>temperature_2m (°C)</th>\n",
       "      <th>relative_humidity_2m (%)</th>\n",
       "      <th>apparent_temperature (°C)</th>\n",
       "      <th>precipitation (mm)</th>\n",
       "      <th>rain (mm)</th>\n",
       "      <th>snowfall (cm)</th>\n",
       "      <th>weather_code (wmo code)</th>\n",
       "      <th>cloud_cover (%)</th>\n",
       "      <th>wind_speed_10m (km/h)</th>\n",
       "      <th>wind_speed_100m (km/h)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-01-01 00:00:00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>99.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-01-01 01:00:00</td>\n",
       "      <td>0.8</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1.6</td>\n",
       "      <td>1.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-01-01 02:00:00</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>4.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-01-01 03:00:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-2.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-01-01 04:00:00</td>\n",
       "      <td>-0.2</td>\n",
       "      <td>99.0</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>4.3</td>\n",
       "      <td>9.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130819</th>\n",
       "      <td>2024-12-03 19:00:00</td>\n",
       "      <td>0.1</td>\n",
       "      <td>53.0</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>30.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130820</th>\n",
       "      <td>2024-12-03 20:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130821</th>\n",
       "      <td>2024-12-03 21:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130822</th>\n",
       "      <td>2024-12-03 22:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130823</th>\n",
       "      <td>2024-12-03 23:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>130824 rows × 11 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Since we have multiple wind speed options (from 10 meters and from 100 meters), let's see which is the closest to the Kaggle training data. Let's also check the difference in temperature, apparent temperature and humidity.",
   "id": "d9798ae47fa69a95"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T20:20:33.002761Z",
     "start_time": "2024-12-05T20:20:24.127387Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "kaggleTrainingData = pd.read_csv('./kaggleData/train.csv')\n",
    "kaggleTrainingData['datetime'] = pd.to_datetime(kaggleTrainingData['datetime'], format='ISO8601')\n",
    "weatherData2010JanTo2024Dec = pd.read_csv('./open-meteo-38.91N77.07W12m.csv', skiprows=[0, 1, 2])\n",
    "weatherData2010JanTo2024Dec['time'] = pd.to_datetime(weatherData2010JanTo2024Dec['time'], format='ISO8601')\n",
    "\n",
    "speed10mErrors = []\n",
    "speed100mErrors = []\n",
    "temperatureErrors = []\n",
    "apparentTemperatureErrors = []\n",
    "humidityErrors = []\n",
    "\n",
    "for idx, row in kaggleTrainingData.iterrows():\n",
    "    weatherRow = weatherData2010JanTo2024Dec[weatherData2010JanTo2024Dec['time'] == row['datetime']]\n",
    "\n",
    "    speed10m = weatherRow.iloc[0]['wind_speed_10m (km/h)']\n",
    "    speed100m = weatherRow.iloc[0]['wind_speed_100m (km/h)']\n",
    "    temp = weatherRow.iloc[0]['temperature_2m (°C)']\n",
    "    atemp = weatherRow.iloc[0]['apparent_temperature (°C)']\n",
    "    humidity = weatherRow.iloc[0]['relative_humidity_2m (%)']\n",
    "\n",
    "    speed10mErrors.append(abs(row['windspeed'] - speed10m))\n",
    "    speed100mErrors.append(abs(row['windspeed'] - speed100m))\n",
    "    temperatureErrors.append(abs(row['temp'] - temp))\n",
    "    apparentTemperatureErrors.append(abs(row['atemp'] - atemp))\n",
    "    humidityErrors.append(abs(row['humidity'] - humidity))\n",
    "\n",
    "\n",
    "def mae(errors):\n",
    "    return math.fsum(errors) / len(errors)\n",
    "\n",
    "\n",
    "print(\"Mean absolute error:\\n\")\n",
    "print(\"Average error with wind speed at 10 meters:\", round(mae(speed10mErrors), 3))\n",
    "print(\"Average error with wind speed at 100 meters:\", round(mae(speed100mErrors), 3))\n",
    "print(\"Average error of temperature:\", round(mae(temperatureErrors), 3))\n",
    "print(\"Average error of apparent temperature:\", round(mae(apparentTemperatureErrors), 3))\n",
    "print(\"Average error of humidity:\", round(mae(humidityErrors), 3))\n",
    "\n",
    "\n",
    "def rmse(errors):\n",
    "    return (math.fsum([x ** 2 for x in errors]) / len(errors)) ** 1 / 2\n",
    "\n",
    "\n",
    "print(\"\\nRoot mean squared error:\\n\")\n",
    "print(\"Average error with wind speed at 10 meters:\", round(rmse(speed10mErrors), 3))\n",
    "print(\"Average error with wind speed at 100 meters:\", round(rmse(speed100mErrors), 3))\n",
    "print(\"Average error of temperature:\", round(rmse(temperatureErrors), 3))\n",
    "print(\"Average error of apparent temperature:\", round(rmse(apparentTemperatureErrors), 3))\n",
    "print(\"Average error of humidity:\", round(rmse(humidityErrors), 3))\n"
   ],
   "id": "5fa2f60975a4f032",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean absolute error:\n",
      "\n",
      "Average error with wind speed at 10 meters: 5.145\n",
      "Average error with wind speed at 100 meters: 7.145\n",
      "Average error of temperature: 5.618\n",
      "Average error of apparent temperature: 10.227\n",
      "Average error of humidity: 8.835\n",
      "\n",
      "Root mean squared error:\n",
      "\n",
      "Average error with wind speed at 10 meters: 21.308\n",
      "Average error with wind speed at 100 meters: 40.513\n",
      "Average error of temperature: 18.676\n",
      "Average error of apparent temperature: 62.278\n",
      "Average error of humidity: 69.505\n"
     ]
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It seems that the error for each parameter is quite severe, but it will suffice if we were to disregard the Kaggle data and only make a private model for predicting Washington D.C. bike rental demand.\n",
    "\n",
    "We have only one more feature left unaccounted for. That feature is `weather`. Thankfully we have the WMO codes for determining that ([WMO code table](https://www.nodc.noaa.gov/archive/arc0021/0002199/1.1/data/0-data/HTML/WMO-CODE/WMO4677.HTM)). We'll have to convert the WMO codes into the Kaggle values, which are\n",
    "- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n",
    "- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n",
    "- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n",
    "- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n",
    "\n",
    "As for the `windspeed` feature, we'll use the values for wind at 10 meters, since the error is lowest for those values.\n"
   ],
   "id": "d7e54c7a5be895b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-05T20:36:49.906432Z",
     "start_time": "2024-12-05T20:35:56.807389Z"
    }
   },
   "cell_type": "code",
   "source": [
    "windspeed_assignments = []\n",
    "weather_assignments = []\n",
    "\n",
    "print()\n",
    "\n",
    "for idx, row in bikesRentedPerHourCombinedData.iterrows():\n",
    "    weatherRow = weatherData2010JanTo2024Dec[weatherData2010JanTo2024Dec['time'] == row['datetime']]\n",
    "    windspeed_assignments.append(weatherRow.iloc[0]['wind_speed_10m (km/h)'])\n",
    "    weatherCode = weatherRow.iloc[0]['weather_code (wmo code)']\n",
    "    if weatherCode < 10:\n",
    "        weather_assignments.append(1)\n",
    "    elif weatherCode < 20:\n",
    "        weather_assignments.append(2)\n",
    "    elif weatherCode < 40:\n",
    "        weather_assignments.append(3)\n",
    "    elif weatherCode < 50:\n",
    "        weather_assignments.append(4)\n",
    "    elif weatherCode < 60:\n",
    "        weather_assignments.append(3)\n",
    "    else:\n",
    "        weather_assignments.append(4)\n",
    "\n",
    "bikesRentedPerHourCombinedData['windspeed'] = windspeed_assignments\n",
    "bikesRentedPerHourCombinedData['weather'] = weather_assignments\n",
    "\n",
    "# Ordering the columns as they are in Kaggle data\n",
    "bikesRentedPerHourCombinedData = bikesRentedPerHourCombinedData[[\n",
    "    'datetime', 'season', 'holiday', 'workingday', 'weather', 'temp', 'atemp', 'humidity', 'windspeed', 'count']]\n",
    "\n",
    "bikesRentedPerHourCombinedData.to_csv('./bikesRentedPerHourCombinedData.csv', index=False)\n",
    "\n",
    "display(bikesRentedPerHourCombinedData)"
   ],
   "id": "1ec63fb247e772c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                  datetime  season  holiday  workingday  weather  temp  atemp  \\\n",
       "0      2010-09-20 11:00:00       3        0           1        1  23.1   21.2   \n",
       "1      2010-09-20 12:00:00       3        0           1        1  24.3   22.7   \n",
       "2      2010-09-20 13:00:00       3        0           1        1  25.1   23.5   \n",
       "3      2010-09-20 14:00:00       3        0           1        1  25.4   23.6   \n",
       "4      2010-09-20 15:00:00       3        0           1        1  25.6   23.2   \n",
       "...                    ...     ...      ...         ...      ...   ...    ...   \n",
       "123728 2024-10-31 19:00:00       4        0           1        1  21.8   20.6   \n",
       "123729 2024-10-31 20:00:00       4        0           1        1  22.3   20.7   \n",
       "123730 2024-10-31 21:00:00       4        0           1        1  21.9   20.2   \n",
       "123731 2024-10-31 22:00:00       4        0           1        1  21.5   19.6   \n",
       "123732 2024-10-31 23:00:00       4        0           1        1  21.3   19.3   \n",
       "\n",
       "        humidity  windspeed  count  \n",
       "0           34.0       13.0      2  \n",
       "1           30.0       12.6     17  \n",
       "2           29.0       12.6     11  \n",
       "3           30.0       12.8      6  \n",
       "4           30.0       13.0     12  \n",
       "...          ...        ...    ...  \n",
       "123728      65.0       18.8   1561  \n",
       "123729      61.0       20.4   1249  \n",
       "123730      61.0       20.4   1182  \n",
       "123731      61.0       20.9    939  \n",
       "123732      60.0       20.5    511  \n",
       "\n",
       "[123733 rows x 10 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2010-09-20 11:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23.1</td>\n",
       "      <td>21.2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2010-09-20 12:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.3</td>\n",
       "      <td>22.7</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2010-09-20 13:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.1</td>\n",
       "      <td>23.5</td>\n",
       "      <td>29.0</td>\n",
       "      <td>12.6</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2010-09-20 14:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.4</td>\n",
       "      <td>23.6</td>\n",
       "      <td>30.0</td>\n",
       "      <td>12.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2010-09-20 15:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>25.6</td>\n",
       "      <td>23.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123728</th>\n",
       "      <td>2024-10-31 19:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.8</td>\n",
       "      <td>20.6</td>\n",
       "      <td>65.0</td>\n",
       "      <td>18.8</td>\n",
       "      <td>1561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123729</th>\n",
       "      <td>2024-10-31 20:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>22.3</td>\n",
       "      <td>20.7</td>\n",
       "      <td>61.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123730</th>\n",
       "      <td>2024-10-31 21:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.9</td>\n",
       "      <td>20.2</td>\n",
       "      <td>61.0</td>\n",
       "      <td>20.4</td>\n",
       "      <td>1182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123731</th>\n",
       "      <td>2024-10-31 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.5</td>\n",
       "      <td>19.6</td>\n",
       "      <td>61.0</td>\n",
       "      <td>20.9</td>\n",
       "      <td>939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123732</th>\n",
       "      <td>2024-10-31 23:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>21.3</td>\n",
       "      <td>19.3</td>\n",
       "      <td>60.0</td>\n",
       "      <td>20.5</td>\n",
       "      <td>511</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>123733 rows × 10 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 47
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
