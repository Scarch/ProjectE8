{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Making Capital Bikeshare system data usable",
   "id": "46889185c62f4528"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Unzipping files\n",
    "\n",
    "We'll add all of the files into a new folder (`/unzippedData`)\n",
    "\n",
    "**Warning**: requires at least 5.63GB of space"
   ],
   "id": "634e9323845fc0f2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T20:34:49.937921Z",
     "start_time": "2024-12-02T20:34:34.229693Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import zipfile\n",
    "\n",
    "for file in os.listdir(\"./capitalBikeshareData\"):\n",
    "    filepath = \"./capitalBikeshareData/\" + file\n",
    "    with zipfile.ZipFile(filepath, 'r') as zip_ref:\n",
    "        zip_ref.extractall(\"./unzippedData\")"
   ],
   "id": "1ece8cde5822e77c",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analysing data before any further data preparation\n",
    "\n",
    "Since we want to work on as much data as possible, we want to combine the data into one csv file. This however requires the csv files to be the same for the most part. The most important part is for each of the csv files to each have similar/same features. Let's check that."
   ],
   "id": "a3a98778fc575ae0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T20:36:10.704403Z",
     "start_time": "2024-12-02T20:34:49.942442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "columnNamesDict = dict()\n",
    "for file in os.listdir(\"./unzippedData\"):\n",
    "    filepath = \"./unzippedData/\" + file\n",
    "    if not os.path.isfile(filepath):\n",
    "        continue\n",
    "    fileDataframe = pd.read_csv(filepath, low_memory=False)\n",
    "    columnNames = \"\"\n",
    "    for name in fileDataframe.columns:\n",
    "        columnNames += name + \", \"\n",
    "    columnNames = columnNames[:-2]\n",
    "    if columnNames not in columnNamesDict:\n",
    "        print(filepath)\n",
    "        print(columnNames + \"\\n\")\n",
    "        columnNamesDict[columnNames] = fileDataframe.columns.values.tolist()\n"
   ],
   "id": "96f92d72aff7a185",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./unzippedData/2010-capitalbikeshare-tripdata.csv\n",
      "Duration, Start date, End date, Start station number, Start station, End station number, End station, Bike number, Member type\n",
      "\n",
      "./unzippedData/202004-capitalbikeshare-tripdata.csv\n",
      "ride_id, rideable_type, started_at, ended_at, start_station_name, start_station_id, end_station_name, end_station_id, start_lat, start_lng, end_lat, end_lng, member_casual\n",
      "\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Csv files before April 2020 have columns `Duration`, `Start date`, `End date`, `Start station number`, `Start station`, `End station number`, `End station`, `Bike number`, `Member type`.\n",
    "\n",
    "Csv files after April 2020 have columns `ride_id`, `rideable_type`, `started_at`, `ended_at`, `start_station_name`, `start_station_id`, `end_station_name`, `end_station_id`, `start_lat`, `start_lng`, `end_lat`, `end_lng`, `member_casual`.\n",
    "\n",
    "These factors make combining datasets difficult.\n"
   ],
   "id": "3de0b71818dff39e"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Combining data into single files based on features\n",
    "\n",
    "Since we have two different sets of column names / features for two different time ranges, we'll try to make one csv file for both sets.\n",
    "\n",
    "**Warning**: takes a long time (~8 minutes) and requires at least 5.63 GB of space"
   ],
   "id": "c915903b62f3bdfb"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T20:42:08.750157Z",
     "start_time": "2024-12-02T20:36:10.736742Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "combinedDataBeforeApril2020 = pd.DataFrame(\n",
    "    {'Duration': [], 'Start date': [], 'End date': [], 'Start station number': [],\n",
    "     'Start station': [], 'End station number': [], 'End station': [], 'Bike number': [],\n",
    "     'Member type': []})\n",
    "\n",
    "combinedDataAfterApril2020 = pd.DataFrame({'ride_id': [], 'rideable_type': [], 'started_at': [], 'ended_at': [],\n",
    "                              'start_station_name': [],\n",
    "                              'start_station_id': [], 'end_station_name': [], 'end_station_id': [], 'start_lat': [],\n",
    "                              'start_lng': [],\n",
    "                              'end_lat': [], 'end_lng': [], 'member_casual': []})\n",
    "\n",
    "columnNamesDict = set()\n",
    "for file in os.listdir(\"./unzippedData\"):\n",
    "    filepath = \"./unzippedData/\" + file\n",
    "\n",
    "    if not os.path.isfile(filepath):\n",
    "        continue\n",
    "\n",
    "    fileDataframe = pd.read_csv(filepath, low_memory=False, dtype=\"string\") # String type is important to not convert integers into floats (becomes a problem by adding .0 to the end of an integer)\n",
    "\n",
    "    if fileDataframe.columns[0] == 'ride_id':\n",
    "        combinedDataAfterApril2020 = pd.concat([combinedDataAfterApril2020, fileDataframe], ignore_index=True)\n",
    "    else:\n",
    "        combinedDataBeforeApril2020 = pd.concat([combinedDataBeforeApril2020, fileDataframe], ignore_index=True)\n",
    "\n",
    "combinedDataAfterApril2020.to_csv('./combinedDataAfterApril2020.csv')\n",
    "\n",
    "combinedDataBeforeApril2020.to_csv('./combinedDataBeforeApril2020.csv')"
   ],
   "id": "a2f8f232afb6bf8c",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Assembling a combined csv file based on common features\n",
    "\n",
    "Since the features after April 2020 are named better, we'll try to use their names.\n",
    "\n",
    "**Warning**: takes a long time and requires at least 5.63 GB of space"
   ],
   "id": "ce532e0257b8ac79"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T20:46:51.012054Z",
     "start_time": "2024-12-02T20:42:08.790131Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Function for assigning correct datatypes\n",
    "def set_data_types_combined(df):\n",
    "    df['started_at'] = pd.to_datetime(df['started_at'], format='ISO8601', yearfirst=True)\n",
    "    df['ended_at'] = pd.to_datetime(df['started_at'], format='ISO8601', yearfirst=True)\n",
    "    df.astype({\"is_member\": \"bool\"})\n",
    "\n",
    "\n",
    "trimmedDataAfterApril2020 = pd.read_csv('./combinedDataAfterApril2020.csv', low_memory=False, index_col=0, dtype={\"Start station number\": \"string\", \"End station number\": \"string\"})\n",
    "trimmedDataAfterApril2020.drop(columns=[\"ride_id\", \"rideable_type\", \"start_lat\", \"end_lat\", \"start_lng\", \"end_lng\"], axis=1, inplace=True)\n",
    "trimmedDataAfterApril2020.columns = [\"started_at\", \"ended_at\", \"start_station_name\", \"start_station_id\", \"end_station_name\", \"end_station_id\", \"is_member\"]\n",
    "trimmedDataAfterApril2020.loc[trimmedDataAfterApril2020['is_member'] == \"member\",'is_member'] = True\n",
    "trimmedDataAfterApril2020.loc[trimmedDataAfterApril2020['is_member'] == \"casual\",'is_member'] = False\n",
    "\n",
    "\n",
    "trimmedDataBeforeApril2020 = pd.read_csv('./combinedDataBeforeApril2020.csv', low_memory=False, index_col=0, dtype={\"start_station_id\": \"string\", \"end_station_id\": \"string\"})\n",
    "trimmedDataBeforeApril2020.drop(columns=[\"Duration\", \"Bike number\"], axis=1, inplace=True)\n",
    "trimmedDataBeforeApril2020.columns = [\"started_at\", \"ended_at\", \"start_station_id\", \"start_station_name\", \"end_station_id\", \"end_station_name\", \"is_member\"]\n",
    "trimmedDataBeforeApril2020.loc[trimmedDataBeforeApril2020['is_member'] == \"Member\",'is_member'] = True\n",
    "trimmedDataBeforeApril2020.loc[trimmedDataBeforeApril2020['is_member'] == \"Casual\",'is_member'] = False\n",
    "\n",
    "combinedData = pd.concat([trimmedDataAfterApril2020, trimmedDataBeforeApril2020], ignore_index=True)\n",
    "set_data_types_combined(combinedData)\n",
    "combinedData.to_csv('./combinedData.csv')"
   ],
   "id": "f41040a714a1872b",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# In-depth analysis",
   "id": "a06ad1108471ee5b"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Analysing data in greater detail\n",
    "\n",
    "Now that we have multiple large datasets, we can do further investigation into how good our data is."
   ],
   "id": "66aba540aa85f17f"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Loading in data if required, takes a long time\n",
    "combinedData = pd.read_csv('./combinedData.csv', low_memory=False, index_col=0, dtype={\"start_station_id\": \"string\", \"end_station_id\": \"string\"})\n",
    "combinedDataAfterApril2020 = pd.read_csv('./combinedDataAfterApril2020.csv')\n",
    "combinedDataBeforeApril2020 = pd.read_csv('./combinedDataBeforeApril2020.csv')"
   ],
   "id": "1ff8b09d4950fa1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-02T20:34:30.354767Z",
     "start_time": "2024-12-02T20:34:12.830846Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(combinedData.isna().sum()/len(combinedData))\n",
    "print(combinedDataAfterApril2020.isna().sum()/len(combinedDataAfterApril2020))\n",
    "print(combinedDataBeforeApril2020.isna().sum()/len(combinedDataAfterApril2020))\n",
    "\n",
    "print()\n",
    "print(combinedData.start_station_id.value_counts())\n",
    "print(combinedData.end_station_id.value_counts())\n",
    "\n"
   ],
   "id": "4eea249849f8b94f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "started_at            0.000000\n",
      "ended_at              0.000000\n",
      "start_station_name    0.046966\n",
      "start_station_id      0.046966\n",
      "end_station_name      0.050064\n",
      "end_station_id        0.050086\n",
      "is_member             0.000000\n",
      "dtype: float64\n",
      "ride_id               0.000000e+00\n",
      "rideable_type         0.000000e+00\n",
      "started_at            0.000000e+00\n",
      "ended_at              0.000000e+00\n",
      "start_station_name    1.027012e-01\n",
      "start_station_id      1.027012e-01\n",
      "end_station_name      1.094751e-01\n",
      "end_station_id        1.095228e-01\n",
      "start_lat             5.822848e-07\n",
      "start_lng             5.822848e-07\n",
      "end_lat               1.550042e-03\n",
      "end_lng               1.550042e-03\n",
      "member_casual         0.000000e+00\n",
      "dtype: float64\n",
      "Duration                0.000000e+00\n",
      "Start date              0.000000e+00\n",
      "End date                0.000000e+00\n",
      "Start station number    0.000000e+00\n",
      "Start station           0.000000e+00\n",
      "End station number      0.000000e+00\n",
      "End station             0.000000e+00\n",
      "Bike number             8.151988e-07\n",
      "Member type             0.000000e+00\n",
      "dtype: float64\n",
      "\n",
      "start_station_id\n",
      "31623          561100\n",
      "31200          445658\n",
      "31258          429279\n",
      "31201          422951\n",
      "31247          401123\n",
      "                ...  \n",
      "31397              29\n",
      "32428              10\n",
      "32902               8\n",
      "31980               4\n",
      "MTL-ECO5-03         2\n",
      "Name: count, Length: 818, dtype: Int64\n",
      "end_station_id\n",
      "31623          583616\n",
      "31200          494362\n",
      "31201          450360\n",
      "31258          425495\n",
      "31247          412870\n",
      "                ...  \n",
      "32428              10\n",
      "32906               8\n",
      "31980               5\n",
      "32909               3\n",
      "MTL-ECO5-03         2\n",
      "Name: count, Length: 820, dtype: Int64\n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
